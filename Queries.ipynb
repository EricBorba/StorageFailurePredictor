{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset specific variables (replace regular_expression by the variables of interest)\n",
    "#%reset_selective <regular_expression>\n",
    "\n",
    "# reset all variables\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from array import *\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import savefig\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import datetime as dt\n",
    "from pymongo import MongoClient\n",
    "from mongoengine import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True, read_preference=Primary(), uuidrepresentation=3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating/Connecting Mongo DB instances\n",
    "\n",
    "# Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
    "#CONNECTION_STRING = \"mongodb+srv://<jgu>:<123>@<cluster-jgu>.mongodb.net/SMARTAttributesFilter\"\n",
    "\n",
    "connect(db='SMARTAttributesFilter', alias='SMARTAttributesFilter_alias')\n",
    "\n",
    "connect(db='FailuresAppsLocation', alias='FailuresAppsLocation_alias')\n",
    "\n",
    "connect(db='SMARTAtt_FailuresAppsLocation', alias='SMARTAtt_FailuresAppsLocation_alias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting document schema\n",
    "\n",
    "class SMARTAtt(Document):\n",
    "     disk_id = FloatField(required=False, default='0')\n",
    "     timestamp = DateTimeField(required=False, default='0')\n",
    "     model_x = StringField(required=False, default='0')\n",
    "     r_sectors = FloatField(required=False, default='0')\n",
    "     u_errors = FloatField(required=False, default='0')\n",
    "     p_failedA = FloatField(required=False, default='0')\n",
    "     p_failedB = FloatField(required=False, default='0')\n",
    "     e_failedA = FloatField(required=False, default='0')\n",
    "     e_failedB = FloatField(required=False, default='0')\n",
    "     n_b_written = FloatField(required=False, default='0')\n",
    "     n_b_read = FloatField(required=False, default='0')\n",
    "     meta = {'db_alias': 'SMARTAttributesFilter_alias'}\n",
    "\n",
    "class FailuresAppsLocation(Document):\n",
    "     disk_id = FloatField(required=False, default='0')\n",
    "     failure_time = DateTimeField(required=False, default='0')\n",
    "     model_x = StringField(required=False, default='0')\n",
    "     model_y = StringField(required=False, default='0')\n",
    "     app = StringField(required=False, default='0')\n",
    "     node_id = FloatField(required=False, default='0')\n",
    "     rack_id = FloatField(required=False, default='0')\n",
    "     machine_room_id = FloatField(required=False, default='0')\n",
    "     meta = {'db_alias': 'FailuresAppsLocation_alias'}\n",
    "\n",
    "class SMARTAtt_FailuresAppsLocation(Document):\n",
    "     smart_att = ReferenceField(SMARTAtt)\n",
    "     failures_app_location = ReferenceField(FailuresAppsLocation)\n",
    "     meta = {'db_alias': 'SMARTAtt_FailuresAppsLocation_alias'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the connection to the DB\n",
    "\n",
    "disconnect(alias='SMARTAttributesFilter_alias')\n",
    "\n",
    "disconnect(alias='FailuresAppsLocation_alias_alias')\n",
    "\n",
    "disconnect(alias='SMARTAtt_FailuresAppsLocation_alias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DAE', 'DB', 'NAS', 'RM', 'SS', 'WPS', 'WS', 'WSM', 'none']\n"
     ]
    }
   ],
   "source": [
    "## Some queries in Mongoengine\n",
    "\n",
    "## Creating the object related to the whole collection\n",
    "#failuresAppsLocationTeste = FailuresAppsLocation.objects()\n",
    "\n",
    "## Collecting the applications\n",
    "apps = FailuresAppsLocation.objects().distinct(\"app\")\n",
    "print(apps)\n",
    "\n",
    "## Looping inside dcuments, which are filtered for the kind o app\n",
    "#for app_c in apps:\n",
    "#   dataPerApp = FailuresAppsLocation.objects(app=app_c).filter()\n",
    "   #dataPerAppToList = list(dataPerApp)\n",
    "   #dataPerAppDf = pd.DataFrame.from_dict(dataPerAppToList)\n",
    "     \n",
    "#   for doc in dataPerApp:\n",
    "#      arrayForDataPerApp = np.append(arrayForDataPerApp, doc.to_json())\n",
    "\n",
    "##The collection size\n",
    "#len(failuresAppsLocationTeste)\n",
    "\n",
    "\n",
    "## Query if you know something about the document\n",
    "#testando = FailuresAppsLocation.objects(disk_id=\"33722\").get()\n",
    "\n",
    "\n",
    "## Query if you know something about the document\n",
    "#SMARTAttributesTest = SMARTAtt.objects(timestamp=\"2019-12-31\").filter().limit(20)\n",
    "#SMARTAttributesTest = SMARTAtt.objects(timestamp=\"2019-12-31\").filter()\n",
    "\n",
    "## Printing\n",
    "#for i in SMARTAttributesTest:\n",
    "#    print(i.timestamp)\n",
    "    \n",
    "## Deleting all collection\n",
    "#failuresAppsLocationTeste.delete() \n",
    "  \n",
    "##Deleting all collection\n",
    "#for i in failuresAppsLocationTeste:\n",
    " # i.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some queries pandas\n",
    "\n",
    "# Find an specific line based on a specific value from a column\n",
    "#df_failuresLocationDocumentsJsonMTTF.loc[df_failuresLocationDocumentsJsonMTTF[\"mtff_node\"] == 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Space for small tests\n",
    "\n",
    "failuresLocationDocuments = FailuresAppsLocation.objects()\n",
    "\n",
    "jSon_failuresLocationDocumentsJson = json.loads(failuresLocationDocuments.to_json())\n",
    "df_failuresLocationDocumentsJson = pd.DataFrame.from_dict(jSon_failuresLocationDocumentsJson) \n",
    "\n",
    "\n",
    "dicDateToString = json.dumps(list(df_failuresLocationDocumentsJson['failure_time']))\n",
    "dicStringToJson = json.loads(dicDateToString)\n",
    "dicJsonToDf = pd.DataFrame.from_dict(dicStringToJson)\n",
    "df_failuresLocationDocumentsJson['failure_time'] = dicJsonToDf['$date']\n",
    "\n",
    "\n",
    "\n",
    "#print(df_failuresLocationDocumentsJson.model_y.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating MTTF per node, rack and general\n",
    "\n",
    "df_failuresLocationDocumentsJsonMTTF = df_failuresLocationDocumentsJson\n",
    "\n",
    "## Value representing: 2018-01-01 00:00:00 (starting date from the experiment)\n",
    "#1514764800000\n",
    "\n",
    "#Subctracting by the initial time of the experiment and turning into hours\n",
    "df_failuresLocationDocumentsJsonMTTF['failure_time'] = df_failuresLocationDocumentsJson.failure_time.sub(1514764800000)\n",
    "df_failuresLocationDocumentsJsonMTTF['failure_time'] = df_failuresLocationDocumentsJson.failure_time.div(1000)\n",
    "df_failuresLocationDocumentsJsonMTTF['failure_time'] = df_failuresLocationDocumentsJson.failure_time.div(60)\n",
    "df_failuresLocationDocumentsJsonMTTF['failure_time'] = df_failuresLocationDocumentsJson.failure_time.div(60)\n",
    "#df_failuresLocationDocumentsJsonMTTF.head(3)\n",
    "\n",
    "# Number of unique values by column\n",
    "#id_apps = df_failuresLocationDocumentsJsonMTTF.app.unique()\n",
    "#id_nodes = df_failuresLocationDocumentsJsonMTTF.node_id.unique()\n",
    "#id_racks = nodes = df_failuresLocationDocumentsJsonMTTF.rack_id.unique()\n",
    "#id_ssds = nodes = df_failuresLocationDocumentsJsonMTTF.disk_id.unique()\n",
    "\n",
    "#Calculating the MTTFs\n",
    "df_general = df_failuresLocationDocumentsJsonMTTF['failure_time'].mean()\n",
    "df_appNode = df_failuresLocationDocumentsJsonMTTF.groupby(['app', 'node_id'])['failure_time'].mean()\n",
    "df_appNode = pd.DataFrame(df_appNode)\n",
    "df_appNode.rename(columns = {'failure_time':'mttf_appNode'}, inplace=True)\n",
    "df_appRack = df_failuresLocationDocumentsJsonMTTF.groupby(['app', 'rack_id'])['failure_time'].mean()\n",
    "df_appRack = pd.DataFrame(df_appRack)\n",
    "df_appRack.rename(columns = {'failure_time':'mttf_appRack'}, inplace=True)\n",
    "df_app = df_failuresLocationDocumentsJsonMTTF.groupby(['app'])['failure_time'].mean()\n",
    "df_app = pd.DataFrame(df_app)\n",
    "df_app.rename(columns = {'failure_time':'mttf_app'}, inplace=True)\n",
    "df_all = df_failuresLocationDocumentsJsonMTTF.groupby(['app', 'rack_id', 'node_id'])['failure_time'].mean()\n",
    "\n",
    "# Merging the results with the original dataframe\n",
    "df_result = pd.merge(df_failuresLocationDocumentsJsonMTTF, df_appNode, how='left', on=['app', 'node_id'])\n",
    "df_result = pd.merge(df_result, df_appRack, how='left', on=['app', 'rack_id'])\n",
    "df_result = pd.merge(df_result, df_app, how='left', on=['app'])\n",
    "\n",
    "# Choosing the columns of interest\n",
    "df_resultFiltered = df_result.loc[:,['app','node_id', 'rack_id','mttf_appNode','mttf_appRack','mttf_app']]\n",
    "df_resultFiltered.to_csv('failuresLocationApp.csv')\n",
    "#df_result.head(30)\n",
    "\n",
    "\n",
    "\n",
    "#df.groupby('Sex').sum().plot(kind='bar');\n",
    "#print(df_app)\n",
    "#df_appNode.groupby(['app']).plot(kind='bar')\n",
    "#df.groupby(['Sex', 'Survived'] )['Survived'].count().plot.bar(figsize=(8, 6));\n",
    "\n",
    "#d1 = data[data[\"City\"] == \"Houston\"]\n",
    "#dataFrame.Reg_Price[i]\n",
    "#df.loc[df['column_name'] == some_value]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating Flash technology\n",
    "\n",
    "flashtech = pd.DataFrame({\n",
    "'model_y':['A3', 'A2', 'B3' , 'B2', 'C1', 'C2'],  \n",
    "'flash': ['MLC', 'MLC', 'MLC' , 'MLC', '3D-TLC', '3D-TLC']})\n",
    "\n",
    "df_flashtech = pd.merge(df_result, flashtech, how='left', on=['model_y'])\n",
    "\n",
    "df_flashtech = df_flashtech.groupby(['app','flash'])['failure_time'].mean()\n",
    "\n",
    "df_flashtech = pd.DataFrame(df_flashtech)\n",
    "\n",
    "df_flashtech.rename(columns = {'failure_time':'mttf_flash'}, inplace=True)\n",
    "\n",
    "df_flashtech.to_csv('flashtech.csv')\n",
    "#df_flashtech.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating Capacity\n",
    "\n",
    "capacity = pd.DataFrame({\n",
    "'model_y':['A3', 'A2', 'B3' , 'B2', 'C1', 'C2'],  \n",
    "'capacity': ['480GB', '800GB', '1920GB' , '1920GB', '1920GB', '960GB']})\n",
    "\n",
    "df_flashtech = pd.merge(df_result, flashtech, how='left', on=['model_y'])\n",
    "\n",
    "df_flashtech = df_flashtech.groupby(['app','flash'])['failure_time'].mean()\n",
    "\n",
    "df_flashtech = pd.DataFrame(df_flashtech)\n",
    "\n",
    "df_flashtech.rename(columns = {'failure_time':'mttf_flash'}, inplace=True)\n",
    "\n",
    "df_flashtech.to_csv('flashtech.csv')\n",
    "#df_flashtech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  Creating Graphs\n",
    "\n",
    "fig = sns.catplot(x=\"app\", y=\"failure_time\", hue=\"model_x\", data=df_failuresLocationDocumentsJson,\n",
    "               row=\"node_id\", col=\"rack_id\", kind=\"bar\", ci=90, palette=\"Blues_d\", aspect=0.9, height=4.5\n",
    "                  , legend_out = True, margin_titles = True)\n",
    "\n",
    "fig.set_axis_labels(\"App\", \"MTTF\")\n",
    "fig.set_xticklabels([\"DAE\", \"DB\", \"NAS\", \"RM\", \"SS\", \"WPS\", \"WS\", \"WSM\", \"none\"])\n",
    "\n",
    "plt.savefig('teste.pdf', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failuresLocationDocumentsJson.to_csv('failuresLocation.csv', index = None, header=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
