{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing System Reliability Metrics using RBD (Reliability Block Diagram) Analysis\n",
    "\n",
    "import pandas as pd\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "def calculate_reliability_block_diagram(mtbf_values, mttr_values, num_blocks_values, system_type, application_names):\n",
    "    \"\"\"\n",
    "    Calculate system mean time between failures (MTBF) and mean time to repair (MTTR) metrics\n",
    "    for different applications using RBD analysis under either series or parallel configuration.\n",
    "\n",
    "    Parameters:\n",
    "    - mtbf_values: List of MTBF (Mean Time Between Failures) values for different applications.\n",
    "    - mttr_values: List of MTTR (Mean Time To Repair) values (currently supports single value).\n",
    "    - num_blocks_values: List of integers specifying number of blocks in the system configuration.\n",
    "    - system_type: Type of system configuration ('series' or 'parallel').\n",
    "    - application_names: List of application names corresponding to each MTBF value.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing computed metrics including Application Name, Number of Blocks, \n",
    "      Input MTBF, Input MTTR, System MTBF, and System MTTR.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError if system_type is not 'series' or 'parallel'.\n",
    "\n",
    "    Note:\n",
    "    - The system assumes all blocks are identical and configured either in series or parallel.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Set decimal precision\n",
    "    getcontext().prec = 10\n",
    "\n",
    "    for mtbf, app_name in zip(mtbf_values, application_names):\n",
    "        for mttr in mttr_values:\n",
    "            for num_blocks in num_blocks_values:\n",
    "                mtbf_decimal = Decimal(mtbf)  # Convert mtbf to Decimal\n",
    "                mttr_decimal = Decimal(mttr)  # Convert mttr to Decimal\n",
    "\n",
    "                if system_type == 'series':\n",
    "                    system_mtbf = Decimal(1) / (sum([Decimal(1) / mtbf_decimal for _ in range(num_blocks)]))\n",
    "                    system_mttr = sum([mttr_decimal for _ in range(num_blocks)])\n",
    "                elif system_type == 'parallel':\n",
    "                    system_mtbf = (((Decimal(1)) / (Decimal(1) / mtbf_decimal)) * (sum([Decimal(1) / i for i in range(1, num_blocks + 1)])))\n",
    "                    system_mttr = mttr_decimal  # MTTR in parallel is the same as individual MTTR\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid system_type. Use 'series' or 'parallel'.\")\n",
    "                \n",
    "                results.append({\n",
    "                    'Application_Name': app_name,\n",
    "                    'Num_Blocks': num_blocks,\n",
    "                    'MTBF_Input': mtbf,\n",
    "                    'MTTR_Input': mttr,\n",
    "                    'System_MTBF': system_mtbf,\n",
    "                    'System_MTTR': system_mttr\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Define application names corresponding to each MTBF value\n",
    "application_names = [\"none\", 'RM', 'WSM', 'Gekko']  # Add more as needed\n",
    "\n",
    "# Load mtbf_values from CSV\n",
    "# mtbf_df = pd.read_csv('mtbf_values.csv')  # Replace 'mtbf_values.csv' with your file name\n",
    "# mtbf_values = mtbf_df['MTBF'].to_numpy()\n",
    "\n",
    "# mttf worst cases for None, RM, and WSM\n",
    "# 64GiB (16 threads * 4GiB) because this is the volume used in GekoFS paper (Total LBAs written, sector size=512bytes)\n",
    "mtbf_values = [987137.8067, 1157597.828, 2025612.832, 1066882,317]\n",
    "mttr_values = [1]\n",
    "num_blocks_values = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "\n",
    "# Specify system type ('series' or 'parallel')\n",
    "system_type = 'series'\n",
    "\n",
    "# Perform experiments and store results in a DataFrame\n",
    "metrics_result = calculate_reliability_block_diagram(mtbf_values, mttr_values, num_blocks_values, system_type, application_names)\n",
    "print(metrics_result)\n",
    "\n",
    "# Save results to CSV (change the filename for the correct algorithm name)\n",
    "metrics_result.to_csv('ExperimentalResults/RBDresultsRF.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Approximating delay distributions of GekkoFS using phase-type distributions\n",
    "## based on moment matching technique and given mean (mu_d) and standard deviation (sigma_d).\n",
    "## This script was developed but not utilized for this article, as the requests were considered exponential.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def phase_approximation(mu_d, sigma_d):\n",
    "    \"\"\"\n",
    "    Approximates the delay distribution of GekkoFS using phase-type distributions based on\n",
    "    the moment matching technique.\n",
    "\n",
    "    Parameters:\n",
    "    - mu_d (float): Mean delay of GekkoFS.\n",
    "    - sigma_d (float): Standard deviation of delay of GekkoFS.\n",
    "\n",
    "    Returns:\n",
    "    - str: Description of the phase-type distribution approximation or \"Unknown distribution\"\n",
    "           if the distribution cannot be determined.\n",
    "    \"\"\"\n",
    "    \n",
    "    cv_inv = mu_d / sigma_d\n",
    "\n",
    "    # Initialize gamma variable with a default value\n",
    "    gamma = 0\n",
    "\n",
    "\n",
    "    # Check for the case when mean and standard deviation are equal\n",
    "    if np.isclose(mu_d, sigma_d):\n",
    "        rate = 1/mu_d\n",
    "        return f\"Single timing transition assumed: rate = {rate}\"\n",
    "\n",
    "    # Check for Erlang subnet\n",
    "    if cv_inv.is_integer() and cv_inv != 1:\n",
    "        gamma = int(cv_inv**2)\n",
    "        rate_lambda = gamma / mu_d\n",
    "        return f\"Erlang subnet: gamma = {gamma}, lambda = {rate_lambda}\"\n",
    "\n",
    "    # Check for hypoexponential subnet (fixing the condition)\n",
    "    if mu_d > sigma_d:\n",
    "        gamma_lower = float(cv_inv**2 - 1)\n",
    "        gamma_upper = float(cv_inv**2)\n",
    "\n",
    "        print(gamma_lower)\n",
    "        print(gamma_upper)\n",
    "        \n",
    "        # Calculate gamma as an integer within the specified range\n",
    "        gamma = int(np.round(np.average([gamma_lower, gamma_upper])))\n",
    "        #gamma =2\n",
    "        mu_1 = (mu_d + np.sqrt(gamma * (gamma + 1) * sigma_d**2 - gamma * mu_d**2)) / (gamma + 1)\n",
    "        mu_2 = (gamma * mu_d - np.sqrt(gamma * (gamma + 1) * sigma_d**2 - gamma * mu_d**2)) / (gamma * (gamma + 1))\n",
    "        lambda_1 = 1 / mu_1\n",
    "        lambda_2 = 1 / mu_2\n",
    "        return f\"Hypoexponential subnet: gamma = {gamma}, lambda_1 = {lambda_1}, lambda_2 = {lambda_2}, mu_1 = {mu_1}, mu_2 = {mu_2}\"\n",
    "\n",
    "    # Check for hyperexponential subnet\n",
    "    if mu_d < sigma_d:\n",
    "        omega_1 = 2 * mu_d**2 / (mu_d**2 + sigma_d**2)\n",
    "        omega_2 = 1 - omega_1\n",
    "        rate_h = 2 * mu_d / (mu_d**2 + sigma_d**2)\n",
    "        return f\"Hyperexponential subnet: omega_1 = {omega_1}, omega_2 = {omega_2}, lambda_h = {rate_h}\"\n",
    "\n",
    "    return \"Unknown distribution\"\n",
    "\n",
    "# Example usage:\n",
    "mu_d_value = 348.17\n",
    "sigma_d_value = 3.8159432\n",
    "\n",
    "result = phase_approximation(mu_d_value, sigma_d_value)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Gekko performance values, calculating phase-type distributions and parameters,\n",
    "# and saving the results into a CSV file.\n",
    "#\n",
    "# This script was developed but not adopted for this article as the requests were considered exponential.\n",
    "#\n",
    "# The phase_approximation function approximates delay distributions of GekkoFS using phase-type distributions\n",
    "# based on moment matching technique, given mean (mu_d) and standard deviation (sigma_d).\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from itertools import zip_longest\n",
    "\n",
    "def phase_approximation(mu_d, sigma_d):\n",
    "    \"\"\"\n",
    "    Approximates delay distributions of GekkoFS using phase-type distributions.\n",
    "    \n",
    "    Parameters:\n",
    "    - mu_d (float): Mean value.\n",
    "    - sigma_d (float): Standard deviation value.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: A tuple containing the distribution type and its parameters as a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    cv_inv = mu_d / sigma_d\n",
    "\n",
    "    # Initialize gamma variable with a default value\n",
    "    gamma = 0\n",
    "\n",
    "    # Check for the case when mean and standard deviation are equal\n",
    "    if np.isclose(mu_d, sigma_d):\n",
    "        rate = 1 / mu_d\n",
    "        return \"Single timing transition assumed\", {\"rate\": rate}\n",
    "\n",
    "    # Check for Erlang subnet\n",
    "    if cv_inv.is_integer() and cv_inv != 1:\n",
    "        gamma = int(cv_inv**2)\n",
    "        rate_lambda = gamma / mu_d\n",
    "        return \"Erlang subnet\", {\"gamma\": gamma, \"lambda\": rate_lambda}\n",
    "\n",
    "    # Check for hypoexponential subnet (fixing the condition)\n",
    "    if mu_d > sigma_d:\n",
    "        gamma_lower = float(cv_inv**2 - 1)\n",
    "        gamma_upper = float(cv_inv**2)\n",
    "\n",
    "        # Calculate gamma as an integer within the specified range\n",
    "        gamma = int(np.round(np.average([gamma_lower, gamma_upper])))\n",
    "        mu_1 = (mu_d + np.sqrt(gamma * (gamma + 1) * sigma_d**2 - gamma * mu_d**2)) / (gamma + 1)\n",
    "        mu_2 = (gamma * mu_d - np.sqrt(gamma * (gamma + 1) * sigma_d**2 - gamma * mu_d**2)) / (gamma * (gamma + 1))\n",
    "        lambda_1 = 1 / mu_1\n",
    "        lambda_2 = 1 / mu_2\n",
    "        return \"Hypoexponential subnet\", {\"gamma\": gamma, \"lambda_1\": lambda_1, \"lambda_2\": lambda_2, \"mu_1\": mu_1, \"mu_2\": mu_2}\n",
    "\n",
    "    # Check for hyperexponential subnet\n",
    "    if mu_d < sigma_d:\n",
    "        omega_1 = 2 * mu_d**2 / (mu_d**2 + sigma_d**2)\n",
    "        omega_2 = 1 - omega_1\n",
    "        rate_h = 2 * mu_d / (mu_d**2 + sigma_d**2)\n",
    "        return \"Hyperexponential subnet\", {\"omega_1\": omega_1, \"omega_2\": omega_2, \"lambda_h\": rate_h}\n",
    "\n",
    "    return \"Unknown distribution\", {}\n",
    "\n",
    "def process_csv_data(write_avg_file_path, write_std_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    Processes Gekko performance data from CSV files, calculates phase-type distributions and parameters,\n",
    "    and saves the results into a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    - write_avg_file_path (str): File path to the CSV file containing write average data.\n",
    "    - write_std_file_path (str): File path to the CSV file containing standard deviation data.\n",
    "    - output_file_path (str): File path to save the processed data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load CSV data for write average\n",
    "    write_avg_data = pd.read_csv(write_avg_file_path, comment='!', skipinitialspace=True, sep=';')\n",
    "\n",
    "    # Load CSV data for standard deviation\n",
    "    write_std_data = pd.read_csv(write_std_file_path, comment='!', skipinitialspace=True, sep=';')\n",
    "\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    result_list = []\n",
    "\n",
    "    # Extract column names from the first row\n",
    "    column_names = write_avg_data.columns.values\n",
    "\n",
    "    # Iterate over rows in the write_avg_data DataFrame\n",
    "    for index, row in write_avg_data.iterrows():\n",
    "        nodes = row.iloc[0]\n",
    "        object_sizes = column_names[1:]\n",
    "\n",
    "        # Clean the \"Mean\" column by extracting numeric values\n",
    "        mean_values = row.iloc[1:].apply(lambda x: float(re.search(r'\\d+\\.\\d+|\\d+', str(x)).group()) if pd.notnull(x) else np.nan)\n",
    "\n",
    "        # Check if the index is within the valid range for write_std_data\n",
    "        if index < len(write_std_data):\n",
    "            # Find the corresponding row in the write_std_data DataFrame\n",
    "            std_row = write_std_data.iloc[index, 1:].apply(lambda x: float(x) if pd.notnull(x) else np.nan)\n",
    "\n",
    "            # Initialize lists to store results and parameters\n",
    "            distribution_results = []\n",
    "            gamma_list = []\n",
    "            lambda_1_list = []\n",
    "            lambda_2_list = []\n",
    "            mu_1_list = []\n",
    "            mu_2_list = []\n",
    "            omega_1_list = []\n",
    "            omega_2_list = []\n",
    "            rate_h_list = []\n",
    "            sigma_d_list = []  \n",
    "\n",
    "            # Iterate over object sizes, mean values, and standard deviation values\n",
    "            for obj_size, mu_d, std_percent in zip_longest(object_sizes, mean_values, std_row, fillvalue=np.nan):\n",
    "                # Calculate absolute standard deviation\n",
    "                sigma_d = mu_d * abs(float(std_percent))\n",
    "                sigma_d_list.append(sigma_d)\n",
    "\n",
    "                # Apply the phase approximation function\n",
    "                result, params = phase_approximation(mu_d, sigma_d)\n",
    "\n",
    "                # Extract parameters for each distribution type\n",
    "                if result == \"Erlang subnet\":\n",
    "                    gamma_list.append(params.get(\"gamma\", np.nan))\n",
    "                    lambda_1_list.append(params.get(\"lambda\", np.nan))\n",
    "                    lambda_2_list.append(np.nan)\n",
    "                    mu_1_list.append(np.nan)\n",
    "                    mu_2_list.append(np.nan)\n",
    "                    omega_1_list.append(np.nan)\n",
    "                    omega_2_list.append(np.nan)\n",
    "                    rate_h_list.append(np.nan)\n",
    "                elif result == \"Hypoexponential subnet\":\n",
    "                    gamma_list.append(params.get(\"gamma\", np.nan))\n",
    "                    lambda_1_list.append(params.get(\"lambda_1\", np.nan))\n",
    "                    lambda_2_list.append(params.get(\"lambda_2\", np.nan))\n",
    "                    mu_1_list.append(params.get(\"mu_1\", np.nan))\n",
    "                    mu_2_list.append(params.get(\"mu_2\", np.nan))\n",
    "                    omega_1_list.append(np.nan)\n",
    "                    omega_2_list.append(np.nan)\n",
    "                    rate_h_list.append(np.nan)\n",
    "                elif result == \"Hyperexponential subnet\":\n",
    "                    gamma_list.append(np.nan)\n",
    "                    lambda_1_list.append(np.nan)\n",
    "                    lambda_2_list.append(np.nan)\n",
    "                    mu_1_list.append(np.nan)\n",
    "                    mu_2_list.append(np.nan)\n",
    "                    omega_1_list.append(params.get(\"omega_1\", np.nan))\n",
    "                    omega_2_list.append(params.get(\"omega_2\", np.nan))\n",
    "                    rate_h_list.append(params.get(\"lambda_h\", np.nan))\n",
    "                else:\n",
    "                    gamma_list.append(np.nan)\n",
    "                    lambda_1_list.append(np.nan)\n",
    "                    lambda_2_list.append(np.nan)\n",
    "                    mu_1_list.append(np.nan)\n",
    "                    mu_2_list.append(np.nan)\n",
    "                    omega_1_list.append(np.nan)\n",
    "                    omega_2_list.append(np.nan)\n",
    "                    rate_h_list.append(np.nan)\n",
    "\n",
    "                # Append the result to the list\n",
    "                distribution_results.append(result)\n",
    "\n",
    "            # Calculate the inverse of mean values\n",
    "            inverse_mean_values = mean_values.apply(lambda x: 1 / x if pd.notnull(x) and x != 0 else np.nan)\n",
    "\n",
    "            # Create a dictionary for each row\n",
    "            row_dict = {\n",
    "                \"Nodes\": [nodes] * len(object_sizes),\n",
    "                \"Object Size\": object_sizes.tolist(),\n",
    "                \"Mean\": mean_values.tolist(),\n",
    "                \"Inverse Mean\": inverse_mean_values.tolist(),  # Add the inverse mean values here\n",
    "                \"Standard Deviation\": std_row.tolist(),\n",
    "                \"Sigma_d\": sigma_d_list,  \n",
    "                \"Distribution\": distribution_results,\n",
    "                \"Gamma\": gamma_list,\n",
    "                \"Lambda_1\": lambda_1_list,\n",
    "                \"Lambda_2\": lambda_2_list,\n",
    "                \"Mu_1\": mu_1_list,\n",
    "                \"Mu_2\": mu_2_list,\n",
    "                \"Omega_1\": omega_1_list,\n",
    "                \"Omega_2\": omega_2_list,\n",
    "                \"Rate_H\": rate_h_list\n",
    "            }\n",
    "\n",
    "            # Append the dictionary to the list of DataFrames\n",
    "            result_list.append(pd.DataFrame(row_dict))\n",
    "        else:\n",
    "            print(f\"Index {index} is out of bounds for write_std_data.\")\n",
    "\n",
    "    # Check if there are DataFrames in the result_list before concatenating\n",
    "    if result_list:\n",
    "        # Concatenate the list of DataFrames\n",
    "        result_df = pd.concat(result_list, ignore_index=True)\n",
    "\n",
    "        # Save the results to a new CSV file\n",
    "        result_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "        # Display the result DataFrame\n",
    "        print(result_df)\n",
    "    else:\n",
    "        print(\"No valid data to concatenate.\")\n",
    "\n",
    "# Specify the file paths for GekkoSeq\n",
    "write_avg_file_path_gekko_seq = \"ExperimentalResults/gekkofs_seq_fpp.csv\"\n",
    "write_std_file_path_gekko_seq = \"ExperimentalResults/gekkofs_seq_fpp_std.csv\"\n",
    "output_file_path_gekko_seq = \"ExperimentalResults/MomentMatchingGekkoSeq.csv\"\n",
    "\n",
    "# Specify the file paths for GekkoRd\n",
    "write_avg_file_path_gekko_rd = \"ExperimentalResults/gekkofs_rd_fpp.csv\"\n",
    "write_std_file_path_gekko_rd = \"ExperimentalResults/gekkofs_rd_fpp_std.csv\"\n",
    "output_file_path_gekko_rd = \"ExperimentalResults/MomentMatchingGekkoRd.csv\"\n",
    "\n",
    "# Process GekkoSeq data\n",
    "process_csv_data(write_avg_file_path_gekko_seq, write_std_file_path_gekko_seq, output_file_path_gekko_seq)\n",
    "\n",
    "# Process GekkoRd data\n",
    "process_csv_data(write_avg_file_path_gekko_rd, write_std_file_path_gekko_rd, output_file_path_gekko_rd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
